<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Peng Tu</title>
  
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/yash_logo.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Peng Tu</name>
              </p>
	      <p>I am a Senior Researcher at MicroBT, where my work is primarily at intersection of Computer Vision and Efficient Deep Learning.
	      </p>
	      <p>
	      I receieved my master's degree from the <a href="https://www.ucas.ac.cn/">University of Chinese Academy of Sciences</a>.
	      My master's years was spent in the <a href="http://www.ict.ac.cn/">Institute of Computing Technology</a> and 
		 <a href="https://www.siat.ac.cn/index_64245.html">Shenzhen Institutes of Advanced Technology</a> of Chinese Academy of Sciences, under
		 the supervision of Prof. <a href="https://scholar.google.com/citations?user=XqdpqNcAAAAJ&hl=en">Jianbin Jiao</a> and 
		 Prof. <a href="https://scholar.google.com/citations?user=gFtI-8QAAAAJ&hl=zh-CN">Yu Qiao</a>.
	      </p>
	      <p>Email: yh.peng.tu@gmail.com
	      </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/pengtu.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/pengtu.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
	      <ul>
		  <li><span style="color:red;font-weight: bold;">[New! 7/2023]</span> A new work (accepted by ICCV2023) building detector by considering energy cost -- <a href="https://arxiv.org/pdf/2301.06719.pdf">FemtoDet</a>, which enables extremely light-weight detectors that strike a balance between energy consumption and performance! &#128522;</li>
		  <li><span style="color:red;font-weight: bold;">[New! 4/2023]</span> Are you tired of dealing with offensive false positives in object detection? Look no further than our latest research -- Triplet ROIAlignment! &#128522;</li>
		  <li><span style="color:red;font-weight: bold;">[New! 11/2021]</span> <a href="https://arxiv.org/abs/2106.15064">GuidedMix-Net</a> was accepted in AAAI 2022! &#128522;</li>
	      </ul>
              </p>
            </td>
          </tr>
	</tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Services</heading>
              <p>
	      <ul>
		 Program Committee of AAAI'23/24.
	      </ul>
              </p>
            </td>
          </tr>
        </tbody></table>
	
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
	    </td>
	  </tr>
	</table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="dirnet_stop()" onmouseover="dirnet_start()">
            <td style="padding:20px;width:33%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dirnet_image'>
                  <img src='images/GuidedMix-Net2.jpg' width=240></div>
		<img src='images/GuidedMix-Net.jpg' width=240>
	      </div>
              <script type="text/javascript">
                function dirnet_start() {
                  document.getElementById('dirnet_image').style.opacity = "1";
                }

                function dirnet_stop() {
                  document.getElementById('dirnet_image').style.opacity = "0";
                }
                dirnet_stop()
              </script>
            </td>
            <td style="padding:20px;width:67%;vertical-align:middle">
                    <a href="https://arxiv.org/abs/2112.14015"><papertitle>GuidedMix-Net: Semi-supervised Semantic Segmentation by Using Labeled Images as Reference
</papertitle></a>
              <br>
	      <strong>Peng Tu*</strong>,
              <a>Yawen Huang</a>,
              <a href="https://scholar.google.co.uk/citations?user=PcmyXHMAAAAJ&hl=en">Feng Zheng</a>,
              <a href="https://scholar.google.com.hk/citations?user=cv8_7usAAAAJ&hl=zh-CN">Zhenyu He</a>,
              <a href="https://scholar.google.com/citations?user=iYEcVaAAAAAJ&hl=zh-CN">Liujun Cao</a>,
	      <a href="https://scholar.google.com/citations?user=z84rLjoAAAAJ&hl=zh-CN">Ling Shao</a>
              <br>
        <em>Association for the Advancement of Artificial Intelligence (AAAI)</em>, 2022
              <br>
              <p>Semi-supervised learning is a challenging problem which aims to construct a model by learning from limited labeled examples. Numerous methods for this by treating labeled and unlabeled data separately often lead to discarding mass prior knowledge learned from the labeled examples. We propose a semi-supervised semantic segmentation method named GudedMix-Net,  which leverages labeled information to guide the learning of unlabeled instances.  Extensive experiments show that GuidedMix-Net significantly improves the mIoU by +7% compared to previous approaches.</p>
            </td>
          </tr>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="dirnet_stop()" onmouseover="dirnet_start()">
            <td style="padding:20px;width:33%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dirnet_image'>
		<img src='images/FemtoDet_vis.png' width=240></div>
              <script type="text/javascript">
                function dirnet_start() {
                  document.getElementById('dirnet_image').style.opacity = "1";
                }

                function dirnet_stop() {
                  document.getElementById('dirnet_image').style.opacity = "0";
                }
                dirnet_stop()
              </script>
            </td>
            <td style="padding:20px;width:67%;vertical-align:middle">
                    <a href="https://arxiv.org/abs/2301.06719"><papertitle>Femtodet: an object detection baseline for energy versus performance tradeoffs
</papertitle></a>
              <br>
	      <strong>Peng Tu*</strong>,
              <a>Xu Xie</a>,
              <a>Guo AI</a>,
              <a>Yuexiang Li</a>,
              <a>Yawen Huang</a>,
	      <a href="https://scholar.google.com/citations?user=vAIECxgAAAAJ&hl=zh-CN">Yefeng Zheng</a>
              <br>
        <em>International Conference on Computer Vision (ICCV)</em>, 2023
              <br>
              <p>Efficient detectors for edge devices are often optimized for parameters or speed count metrics, which remain in weak correlation with the energy of detectors. However, some vision applications of convolutional neural networks, such as always-on surveillance cameras, are critical for energy constraints. This paper aims to serve as a baseline by designing detectors to reach tradeoffs between energy and performance from two perspectives: 1) We extensively analyze various CNNs to identify low-energy architectures, including selecting activation functions, convolutions operators, and feature fusion structures on necks. These underappreciated details in past work seriously affect the energy consumption of detectors; 2) To break through the dilemmatic energy-performance problem, we propose a balanced detector driven by energy using discovered low-energy components named FemtoDet. In addition to the novel construction, we improve FemtoDet by considering convolutions and training strategy optimizations. Specifically, we develop a new instance boundary enhancement (IBE) module for convolution optimization to overcome the contradiction between the limited capacity of CNNs and detection tasks in diverse spatial representations, and propose a recursive warm-restart (RecWR) for optimizing training strategy to escape the sub-optimization of light-weight detectors by considering the data shift produced in popular augmentations. As a result, FemtoDet with only 68.77k parameters achieves a competitive score of 46.3 AP50 on PASCAL VOC and 1.11 W & 64.47 FPS on Qualcomm Snapdragon 865 CPU platforms. Extensive experiments on COCO and TJUDHD datasets indicate that the proposed method achieves competitive results in diverse scenes</p>
            </td>
          </tr>
			
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
	      Website template borrowed from <a href="https://jonbarron.info">here</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
